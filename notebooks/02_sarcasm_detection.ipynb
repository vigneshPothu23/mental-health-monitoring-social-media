{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc3c4fb3-3125-4d3f-aa34-df14da793b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8731c45a-dbf3-4bcc-bdc3-797d32e4b3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sarc = pd.read_csv(\"train-balanced-sarcasm.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c532b21a-c0a8-4f1e-b3a8-ca2fb39a9e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sarc = pd.read_csv(\"train-balanced-sarcasm.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bafd757a-6ecd-4be5-a335-07b8c8d00a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-10-16 23:55:23</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-11</td>\n",
       "      <td>2016-11-01 00:24:10</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>2016-09-22 21:45:37</td>\n",
       "      <td>They're favored to win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>icebrotha</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>-8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-10-18 21:03:47</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>cush2push</td>\n",
       "      <td>MaddenUltimateTeam</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-12</td>\n",
       "      <td>2016-12-30 17:00:13</td>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment     author  \\\n",
       "0      0                                         NC and NH.  Trumpbart   \n",
       "1      0  You do know west teams play against west teams...  Shbshb906   \n",
       "2      0  They were underdogs earlier today, but since G...   Creepeth   \n",
       "3      0  This meme isn't funny none of the \"new york ni...  icebrotha   \n",
       "4      0                    I could use one of those tools.  cush2push   \n",
       "\n",
       "            subreddit  score  ups  downs     date          created_utc  \\\n",
       "0            politics      2   -1     -1  2016-10  2016-10-16 23:55:23   \n",
       "1                 nba     -4   -1     -1  2016-11  2016-11-01 00:24:10   \n",
       "2                 nfl      3    3      0  2016-09  2016-09-22 21:45:37   \n",
       "3  BlackPeopleTwitter     -8   -1     -1  2016-10  2016-10-18 21:03:47   \n",
       "4  MaddenUltimateTeam      6   -1     -1  2016-12  2016-12-30 17:00:13   \n",
       "\n",
       "                                      parent_comment  \n",
       "0  Yeah, I get that argument. At this point, I'd ...  \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...  \n",
       "2                            They're favored to win.  \n",
       "3                         deadass don't kill my buzz  \n",
       "4  Yep can confirm I saw the tool they use for th...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sarc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ffaa6f2-540f-4624-a455-7823610798a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1010826, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sarc.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c798b423-84b0-491f-b91a-029f1f27ac60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    505413\n",
       "1    505413\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sarc[\"label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c11997f6-759d-40f0-b6fe-0ab5acad1fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'comment', 'author', 'subreddit', 'score', 'ups', 'downs',\n",
       "       'date', 'created_utc', 'parent_comment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sarc.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88fcd018-1876-470b-bdc1-4c720b78b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sarc = df_sarc.rename(columns={\n",
    "    \"comment\": \"text\",\n",
    "    \"label\": \"sarcasm\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffbb3d82-fbe7-4429-ae24-12606aa9be6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sarcasm\n",
       "0                                         NC and NH.        0\n",
       "1  You do know west teams play against west teams...        0\n",
       "2  They were underdogs earlier today, but since G...        0\n",
       "3  This meme isn't funny none of the \"new york ni...        0\n",
       "4                    I could use one of those tools.        0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sarc = df_sarc[[\"text\", \"sarcasm\"]]\n",
    "df_sarc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed0120b6-e4b1-46a2-8e58-71ed37291563",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sarc[\"text\"] = df_sarc[\"text\"].astype(str)\n",
    "df_sarc = df_sarc.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9f0dd96-06b3-4bb2-b897-fb25c26be300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>888048</th>\n",
       "      <td>Everyone knows that they're the greatest thing...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847288</th>\n",
       "      <td>Por que no los dos?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961275</th>\n",
       "      <td>The refs are giving this game to the Thunder.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982195</th>\n",
       "      <td>It was a unit joke... cm vs m .... No offense</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787865</th>\n",
       "      <td>Point Reyes isn't in the OC!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  sarcasm\n",
       "888048  Everyone knows that they're the greatest thing...        1\n",
       "847288                                Por que no los dos?        0\n",
       "961275      The refs are giving this game to the Thunder.        1\n",
       "982195      It was a unit joke... cm vs m .... No offense        0\n",
       "787865                       Point Reyes isn't in the OC!        1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sarc.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5fd9feb-eb42-4aa3-ac7f-96831b4b44e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sarcasm\n",
       "0                                         NC and NH.        0\n",
       "1  You do know west teams play against west teams...        0\n",
       "2  They were underdogs earlier today, but since G...        0\n",
       "3  This meme isn't funny none of the \"new york ni...        0\n",
       "4                    I could use one of those tools.        0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sarc = df_sarc.rename(columns={\n",
    "    \"comment\": \"text\",\n",
    "    \"label\": \"sarcasm\"\n",
    "})\n",
    "\n",
    "df_sarc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29ca7e0e-600a-43ae-baa2-c7f44f5eee5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text       0\n",
       "sarcasm    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sarc.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05c4aafc-b800-43d9-8d99-f326115e0da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(808660, 202166)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4b2f848-3f7a-4ba0-b79a-703b0b82fed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assume df_sarc already loaded\n",
    "X = df_sarc[\"text\"].astype(str).tolist()\n",
    "y = df_sarc[\"sarcasm\"].tolist()   # 0 = non-sarcasm, 1 = sarcasm\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72eb584b-8a3e-4e41-9fdd-e89cdd67c506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(808660, 202166)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e98de139-50aa-4933-bc58-38a663678291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\n",
    "    \"distilbert-base-uncased\"\n",
    ")\n",
    "\n",
    "train_encodings = tokenizer(\n",
    "    X_train,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128\n",
    ")\n",
    "\n",
    "test_encodings = tokenizer(\n",
    "    X_test,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da5d9ffe-e860-4335-b735-41b3005cd139",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_encodings)\n",
    "train_encodings.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b70b772a-0839-40f7-ac75-b035cd58dc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SarcasmDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = SarcasmDataset(train_encodings, y_train)\n",
    "eval_dataset = SarcasmDataset(test_encodings, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b052ad6-3cb3-4d3f-b88a-cb20a1f2a6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([ 101, 2430, 4307,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(0)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)\n",
    "train_dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2509f0af-2573-42eb-8f96-d699b92f0d61",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DistilBertForSequenceClassification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mDistilBertForSequenceClassification\u001b[49m.from_pretrained(\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdistilbert-base-uncased\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     num_labels=\u001b[32m2\u001b[39m\n\u001b[32m      4\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'DistilBertForSequenceClassification' is not defined"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3fc97bde-26ac-43f5-a082-8694b8bc8b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c55ea85b-fab7-42f1-abd7-04001cb2d335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b267d06-7b77-4588-9ac8-56a2bc311cd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TrainingArguments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Training config (CPU-friendly)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m training_args = \u001b[43mTrainingArguments\u001b[49m(\n\u001b[32m      3\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33m./sarcasm_results\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     max_steps=\u001b[32m300\u001b[39m,           \u001b[38;5;66;03m# same as before\u001b[39;00m\n\u001b[32m      5\u001b[39m     per_device_train_batch_size=\u001b[32m8\u001b[39m,\n\u001b[32m      6\u001b[39m     per_device_eval_batch_size=\u001b[32m8\u001b[39m,\n\u001b[32m      7\u001b[39m     logging_steps=\u001b[32m50\u001b[39m,\n\u001b[32m      8\u001b[39m     save_strategy=\u001b[33m\"\u001b[39m\u001b[33mno\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     report_to=\u001b[33m\"\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     use_cpu=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     11\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'TrainingArguments' is not defined"
     ]
    }
   ],
   "source": [
    "# Training config (CPU-friendly)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sarcasm_results\",\n",
    "    max_steps=300,           # same as before\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\",\n",
    "    use_cpu=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e298d222-de1e-471e-81a3-861071642ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e03f05e-1c99-4a29-b3cf-c64500db3ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training config (CPU-friendly)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sarcasm_results\",\n",
    "    max_steps=300,           # same as before\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\",\n",
    "    use_cpu=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db26e4a1-6d98-480c-8078-47c979b9a922",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m trainer = \u001b[43mTrainer\u001b[49m(\n\u001b[32m      2\u001b[39m     model=model,\n\u001b[32m      3\u001b[39m     args=training_args,\n\u001b[32m      4\u001b[39m     train_dataset=train_dataset,\n\u001b[32m      5\u001b[39m     eval_dataset=eval_dataset\n\u001b[32m      6\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'Trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c6c6ced-6c2c-47f8-aa65-f7304f387c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1d81f33c-5d41-479b-987c-cec612212f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7aeef205-3652-4b0e-8872-51b87ee576b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 09:24, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.695600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.689300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.667400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.611300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.630600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.675100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=300, training_loss=0.6615681521097819, metrics={'train_runtime': 567.5929, 'train_samples_per_second': 4.228, 'train_steps_per_second': 0.529, 'total_flos': 79480439193600.0, 'train_loss': 0.6615681521097819, 'epoch': 0.0029678580968115313})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c5b2fd2-669e-4187-af6b-ca0820014279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('distilbert_sarcasm_model\\\\tokenizer_config.json',\n",
       " 'distilbert_sarcasm_model\\\\special_tokens_map.json',\n",
       " 'distilbert_sarcasm_model\\\\vocab.txt',\n",
       " 'distilbert_sarcasm_model\\\\added_tokens.json',\n",
       " 'distilbert_sarcasm_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"distilbert_sarcasm_model\")\n",
    "tokenizer.save_pretrained(\"distilbert_sarcasm_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afad3abf-d43d-4bad-b504-9f855a2f867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# A. IMPORTS (must re-run)\n",
    "# ===============================\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast,\n",
    "    DistilBertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a5edcef-618a-4b3c-9392-86218c1c8b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sarcasm\n",
       "0                                         NC and NH.        0\n",
       "1  You do know west teams play against west teams...        0\n",
       "2  They were underdogs earlier today, but since G...        0\n",
       "3  This meme isn't funny none of the \"new york ni...        0\n",
       "4                    I could use one of those tools.        0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================\n",
    "# B. LOAD SARCASTIC DATASET\n",
    "# ===============================\n",
    "# Example file name â€“ adjust if different\n",
    "df = pd.read_csv(\"train-balanced-sarcasm.csv\")\n",
    "\n",
    "# Keep only needed columns\n",
    "df = df[[\"comment\", \"label\"]]\n",
    "df = df.dropna()\n",
    "\n",
    "df = df.rename(columns={\n",
    "    \"comment\": \"text\",\n",
    "    \"label\": \"sarcasm\"\n",
    "})\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e9fd988-b048-4f02-8117-95357f1007d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sarcasm\n",
       "0                                         NC and NH.        0\n",
       "1  You do know west teams play against west teams...        0\n",
       "2  They were underdogs earlier today, but since G...        0\n",
       "3  This meme isn't funny none of the \"new york ni...        0\n",
       "4                    I could use one of those tools.        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================\n",
    "# B. LOAD SARCASTIC DATASET\n",
    "# ===============================\n",
    "# Example file name â€“ adjust if different\n",
    "df = pd.read_csv(\"train-balanced-sarcasm.csv\")\n",
    "\n",
    "# Keep only needed columns\n",
    "df = df[[\"comment\", \"label\"]]\n",
    "df = df.dropna()\n",
    "\n",
    "df = df.rename(columns={\n",
    "    \"comment\": \"text\",\n",
    "    \"label\": \"sarcasm\"\n",
    "})\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "996720c2-f094-4db0-a8dc-a18072e0a81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# C. TRAIN / TEST SPLIT\n",
    "# ===============================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"].tolist(),\n",
    "    df[\"sarcasm\"].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f121daf-27bc-4ad1-92c2-727ca6059993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# D. TOKENIZER\n",
    "# ===============================\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\n",
    "    \"distilbert-base-uncased\"\n",
    ")\n",
    "\n",
    "train_encodings = tokenizer(\n",
    "    X_train,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128\n",
    ")\n",
    "\n",
    "test_encodings = tokenizer(\n",
    "    X_test,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e96c20fc-7198-431a-bf11-4afe5b02d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# E. TORCH DATASET\n",
    "# ===============================\n",
    "class SarcasmDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = SarcasmDataset(train_encodings, y_train)\n",
    "eval_dataset = SarcasmDataset(test_encodings, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33be22b1-9ef8-47cf-b34b-6abfe9009c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================\n",
    "# F. LOAD MODEL (CONTINUE LEARNING)\n",
    "# ===============================\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e977fed6-ccb2-4106-9cb7-9edf53c8ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# G. TRAINING ARGS (NEXT +300 STEPS)\n",
    "# ===============================\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sarcasm_results\",\n",
    "    max_steps=600,              # ðŸ”¥ CONTINUE to 600\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\",\n",
    "    use_cpu=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f46d7998-2fc9-42ce-ac08-b27fc05e58c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# H. TRAINER\n",
    "# ===============================\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d10d9e2-9bbe-41d4-b321-e57b835efbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 17:26, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.694000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.683100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.663300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.665200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.655700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.628600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.603500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.630200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.628300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.614700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.582500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.609100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=600, training_loss=0.6381821727752686, metrics={'train_runtime': 1048.8544, 'train_samples_per_second': 4.576, 'train_steps_per_second': 0.572, 'total_flos': 158960878387200.0, 'train_loss': 0.6381821727752686, 'epoch': 0.005936068541804763})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================\n",
    "# I. TRAIN (THIS IS THE +300)\n",
    "# ===============================\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b275677a-047b-4dbe-ae86-5ba3ca14dada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('distilbert_sarcasm_model\\\\tokenizer_config.json',\n",
       " 'distilbert_sarcasm_model\\\\special_tokens_map.json',\n",
       " 'distilbert_sarcasm_model\\\\vocab.txt',\n",
       " 'distilbert_sarcasm_model\\\\added_tokens.json',\n",
       " 'distilbert_sarcasm_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================\n",
    "# J. SAVE MODEL (IMPORTANT)\n",
    "# ===============================\n",
    "model.save_pretrained(\"distilbert_sarcasm_model\")\n",
    "tokenizer.save_pretrained(\"distilbert_sarcasm_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d0809-f4c6-4118-bad1-cf795400495f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
